{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detections_plot(results, img):\n",
    "        detections = []\n",
    "        confidences = []\n",
    "        classes = []\n",
    "        \n",
    "        for r in results:\n",
    "            for box in r.boxes:\n",
    "                x1,y1,x2,y2 = box.xyxy[0]\n",
    "                \n",
    "                x1 = int(x1)\n",
    "                y1 = int(y1)\n",
    "                x2 = int(x2)\n",
    "                y2 = int(y2)\n",
    "                \n",
    "                width = x2-x1\n",
    "                height = y2-y1\n",
    "            \n",
    "                cls = int(box.cls[0])\n",
    "                currentClass = model.model.names[cls]\n",
    "                confidence = math.ceil(box.conf[0]*100)/100\n",
    "                # print (cls)\n",
    "                # if conf > 0.5 and cls in (1,2,3,5,7):\n",
    "                if confidence > 0.5:\n",
    "                    detections.append([x1,y1,width,height])\n",
    "                    confidences.append(confidence)\n",
    "                    classes.append(currentClass)\n",
    "                    \n",
    "        return detections, confidences, classes, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track(detections,confidences, classes, img, tracker):\n",
    "        upd_tracks = []\n",
    "        for i in range(0, len(classes)):\n",
    "            upd_tracks.append((detections[i],confidences[i],classes[i]))\n",
    "            \n",
    "        tracks = tracker.update_tracks(upd_tracks, frame=img)\n",
    "    \n",
    "        for track in tracks:\n",
    "            if not track.is_confirmed():\n",
    "                continue\n",
    "\n",
    "            x1 = int(track.to_ltrb()[0])\n",
    "            y1 = int(track.to_ltrb()[1])\n",
    "            x2 = int(track.to_ltrb()[2])\n",
    "            y2 = int(track.to_ltrb()[3])\n",
    "        \n",
    "            cv2.rectangle(img, (x1,y1),(x2,y2), thickness=2, color=(255,0,25))\n",
    "            cv2.putText(img, f'ID: {track.track_id}', (x1,y1-10),fontFace=cv2.FONT_HERSHEY_DUPLEX , fontScale=0.9, color=(36,255,12), thickness=1)\n",
    "       \n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary (fused): 168 layers, 3007988 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "# model = YOLO('yolov8n.pt') \n",
    "model = YOLO('mojY8nC2E30.pt')\n",
    "model.fuse()\n",
    "video = (r'Videos\\4K Road traffic video for object detection and tracking - free download now!.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 4s, 1 9, 199.6ms\n",
      "Speed: 17.0ms preprocess, 199.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 4s, 1 9, 316.0ms\n",
      "Speed: 9.5ms preprocess, 316.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 4s, 1 9, 231.4ms\n",
      "Speed: 0.0ms preprocess, 231.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 4s, 1 9, 142.2ms\n",
      "Speed: 0.0ms preprocess, 142.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 4s, 1 9, 129.3ms\n",
      "Speed: 0.0ms preprocess, 129.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 4s, 1 9, 162.8ms\n",
      "Speed: 0.0ms preprocess, 162.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 4s, 1 9, 249.8ms\n",
      "Speed: 0.0ms preprocess, 249.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 4s, 1 9, 266.7ms\n",
      "Speed: 0.0ms preprocess, 266.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 4s, 1 9, 183.3ms\n",
      "Speed: 16.6ms preprocess, 183.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 4s, 1 9, 133.0ms\n",
      "Speed: 0.0ms preprocess, 133.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 4s, 1 9, 127.3ms\n",
      "Speed: 3.0ms preprocess, 127.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 4s, 1 9, 132.0ms\n",
      "Speed: 0.0ms preprocess, 132.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 4s, 1 9, 149.6ms\n",
      "Speed: 0.0ms preprocess, 149.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 4s, 1 9, 145.6ms\n",
      "Speed: 3.2ms preprocess, 145.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 4s, 1 9, 141.0ms\n",
      "Speed: 3.0ms preprocess, 141.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 4s, 1 9, 158.2ms\n",
      "Speed: 3.1ms preprocess, 158.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 4s, 1 9, 144.9ms\n",
      "Speed: 3.0ms preprocess, 144.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 4s, 1 9, 139.9ms\n",
      "Speed: 0.9ms preprocess, 139.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 4s, 1 9, 143.3ms\n",
      "Speed: 6.4ms preprocess, 143.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 4s, 1 9, 147.8ms\n",
      "Speed: 2.9ms preprocess, 147.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 4s, 1 9, 153.7ms\n",
      "Speed: 5.4ms preprocess, 153.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 4s, 1 9, 150.5ms\n",
      "Speed: 0.0ms preprocess, 150.5ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 4s, 1 9, 149.8ms\n",
      "Speed: 0.0ms preprocess, 149.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 4s, 1 9, 146.5ms\n",
      "Speed: 0.0ms preprocess, 146.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 4s, 1 8, 1 9, 147.2ms\n",
      "Speed: 18.1ms preprocess, 147.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 4s, 1 8, 1 9, 147.0ms\n",
      "Speed: 2.0ms preprocess, 147.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 4s, 1 8, 1 9, 166.0ms\n",
      "Speed: 0.0ms preprocess, 166.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 4s, 1 9, 140.6ms\n",
      "Speed: 15.6ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 4s, 1 9, 153.4ms\n",
      "Speed: 15.6ms preprocess, 153.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 4s, 1 9, 127.7ms\n",
      "Speed: 15.6ms preprocess, 127.7ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 4s, 1 9, 150.8ms\n",
      "Speed: 0.0ms preprocess, 150.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 4s, 1 9, 149.5ms\n",
      "Speed: 0.0ms preprocess, 149.5ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 4s, 1 9, 158.0ms\n",
      "Speed: 0.0ms preprocess, 158.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 4s, 1 9, 150.2ms\n",
      "Speed: 0.0ms preprocess, 150.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 4s, 1 9, 152.9ms\n",
      "Speed: 0.0ms preprocess, 152.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "2.1140610150199204 FPS\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(video)\n",
    "assert cap.isOpened()\n",
    "tracker = DeepSort()\n",
    "\n",
    "start = time.time()\n",
    "br = 0\n",
    "while True:\n",
    "    ret ,img = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    br+=1\n",
    "    \n",
    "    results = model(img, stream=True)\n",
    "    detections, confidences, classes, img = detections_plot(results, img) \n",
    "    detect_frame = track(detections, confidences, classes, img, tracker)\n",
    "        \n",
    "    cv2.imshow('Pracenje', detect_frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "end = time.time()\n",
    "print(br/(end-start),'FPS')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
